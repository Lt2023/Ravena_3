{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3049ca18-e56f-459d-ae11-88a750225bd9",
   "metadata": {},
   "source": [
    "# 1.修改train_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259956d-fab1-4394-b4bd-04ccfb7c7511",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "下列只展示格式示例,文件在主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a6aa8-47af-4f47-9c1f-ad25ccf25f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"question\": \"你是谁？\",\n",
    "      \"answer\": \"我是一个语言模型。\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"今天的天气如何？\",\n",
    "      \"answer\": \"今天天气晴，适合出门。\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad784ead-db5d-406a-aeba-4ac65ecb1241",
   "metadata": {},
   "source": [
    "# 2.训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2cf2e-0171-455c-b1e2-24e830f8eb90",
   "metadata": {},
   "source": [
    "你可以在主目录下找到train.py或者运行下列代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ddfcf-6bfa-4a1a-88ab-1e732a482886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LanguageModel\n",
    "\n",
    "def main():\n",
    "    model = LanguageModel()  \n",
    "    print(\"开始训练模型...\")\n",
    "    model.train(epochs=1000)  \n",
    "    print(\"训练完成！\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3fc93-527f-4a85-b322-60c5a6b4f5d1",
   "metadata": {},
   "source": [
    "# 3.查看tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307c56dc-7ce4-4281-af4d-930a46f429f4",
   "metadata": {},
   "source": [
    "本项目提供了文件实现Tokenizer可读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c5045-9ba7-4509-b0db-0673ea573d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from termcolor import colored\n",
    "\n",
    "def display_tokenizer(tokenizer_file='model/tokenizer.json', output_file='Ravena_tokenizer_output.txt'):\n",
    "    \n",
    "\n",
    "    try:\n",
    "        with open(tokenizer_file, 'r', encoding='utf-8') as file:\n",
    "            tokenizer_data = json.load(file)\n",
    "        print(colored(f\"成功加载Tokenizer文件: {tokenizer_file}\", \"green\"))\n",
    "    except FileNotFoundError:\n",
    "        print(colored(f\"未找到Tokenizer文件: {tokenizer_file}\", \"red\"))\n",
    "        return\n",
    "    \n",
    "\n",
    "    from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "    tokenizer = tokenizer_from_json(tokenizer_data)\n",
    "    \n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as output:\n",
    "            output.write(\"Tokenizer 词汇表：\\n\")\n",
    "            for word, index in word_index.items():\n",
    "                output.write(f\"{word}: {index}\\n\")\n",
    "        \n",
    "        print(colored(f\"词汇表已成功保存到: {output_file}\", \"green\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(colored(f\"保存词汇表时发生错误: {str(e)}\", \"red\"))\n",
    "        return\n",
    "    \n",
    "    print(colored(\"Tokenizer 词汇表（部分）:\", \"yellow\"))\n",
    "    for i, (word, index) in enumerate(word_index.items()):\n",
    "        print(f\"{word}: {index}\")\n",
    "        if i >= 5000:  \n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    display_tokenizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59350f8-3f5d-443a-b519-7232ab6d83e5",
   "metadata": {},
   "source": [
    "# 4.微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed59bf6-2b71-4536-9c19-a9275ea199a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "您需要修改new_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8338afd-9870-4ed4-bc8e-ac3863ab910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "import random\n",
    "import pickle\n",
    "import jieba\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.layers import Layer\n",
    "import re\n",
    "\n",
    "\n",
    "# 自定义的 PositionalEncoding 层\n",
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, max_len, model_dim, trainable=True, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(trainable=trainable, **kwargs)\n",
    "        self.max_len = max_len\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # 计算位置编码\n",
    "        position = np.arange(self.max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, self.model_dim, 2) * -(np.log(10000.0) / self.model_dim))\n",
    "        pos_encoding = np.zeros((self.max_len, self.model_dim))\n",
    "        pos_encoding[:, 0::2] = np.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = np.cos(position * div_term)\n",
    "        \n",
    "        # 将预计算的 pos_encoding 作为权重，不使用 Keras 初始化器\n",
    "        self.pos_encoding = tf.Variable(initial_value=pos_encoding, trainable=False, dtype=tf.float32, name='pos_encoding')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEncoding, self).get_config()\n",
    "        config.update({\n",
    "            'max_len': self.max_len,\n",
    "            'model_dim': self.model_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class FineTuningTool:\n",
    "    def __init__(self, model_file='model/.Ravena-LLM_Model.keras', tokenizer_file='model/tokenizer.json', faq_file='model/.faq_data.pkl', max_seq_length=20, vocab_size=10000):\n",
    "        # 将模型保存路径设置为 models 文件夹，并使用 .keras 后缀\n",
    "        self.model_file = model_file\n",
    "        self.tokenizer_file = tokenizer_file\n",
    "        self.faq_file = faq_file\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # 加载模型和Tokenizer\n",
    "        self.model = self._load_model()\n",
    "        self.tokenizer = self._load_tokenizer()\n",
    "\n",
    "        # 初始化FAQ数据\n",
    "        self.faq_data = self._load_faq_data()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"加载模型，如果文件不存在则返回None\"\"\"\n",
    "        if os.path.exists(self.model_file):\n",
    "            return load_model(self.model_file, custom_objects={'PositionalEncoding': PositionalEncoding})\n",
    "        else:\n",
    "            print(f\"模型文件 {self.model_file} 不存在，无法进行微调。请先训练模型。\")\n",
    "            return None\n",
    "\n",
    "    def _load_tokenizer(self):\n",
    "        \"\"\"加载Tokenizer，如果文件不存在则返回None\"\"\"\n",
    "        if os.path.exists(self.tokenizer_file):\n",
    "            with open(self.tokenizer_file, 'r', encoding='utf-8') as f:\n",
    "                tokenizer_json = json.load(f)\n",
    "                return tokenizer_from_json(tokenizer_json)\n",
    "        else:\n",
    "            print(f\"Tokenizer文件 {self.tokenizer_file} 不存在，无法进行微调。请先训练模型。\")\n",
    "            return None\n",
    "\n",
    "    def _load_faq_data(self):\n",
    "        \"\"\"加载FAQ数据，如果文件不存在则初始化为空字典\"\"\"\n",
    "        if os.path.exists(self.faq_file):\n",
    "            with open(self.faq_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def _save_faq_data(self):\n",
    "        \"\"\"保存FAQ数据\"\"\"\n",
    "        os.makedirs(os.path.dirname(self.faq_file), exist_ok=True)\n",
    "        with open(self.faq_file, 'wb') as f:\n",
    "            pickle.dump(self.faq_data, f)\n",
    "\n",
    "    def augment_data(self, data):\n",
    "        \"\"\"数据增强：打乱词序和随机插入/删除词语\"\"\"\n",
    "        augmented_data = []\n",
    "        for item in data:\n",
    "            words = item.split()\n",
    "            random.shuffle(words)  # 打乱顺序\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                words.append(random.choice(words))  # 随机插入词语\n",
    "            if len(words) > 2 and random.random() > 0.5:\n",
    "                words.remove(random.choice(words))  # 随机移除词语\n",
    "\n",
    "            augmented_data.append(' '.join(words))\n",
    "        return augmented_data\n",
    "\n",
    "    def prepare_data(self, questions, answers):\n",
    "        \"\"\"处理问题和答案，进行分词并生成序列\"\"\"\n",
    "        # 数据增强\n",
    "        questions = self.augment_data(questions)\n",
    "        answers = self.augment_data(answers)\n",
    "\n",
    "        # 进行分词\n",
    "        questions = [\" \".join(jieba.cut(q)) for q in questions]\n",
    "        answers = [\" \".join(jieba.cut(a)) for a in answers]\n",
    "\n",
    "        # 将文本转换为序列\n",
    "        question_sequences = pad_sequences(self.tokenizer.texts_to_sequences(questions), maxlen=self.max_seq_length)\n",
    "        answer_sequences = [self.tokenizer.texts_to_sequences([a])[0] for a in answers]\n",
    "        answer_sequences = np.array([seq[0] for seq in answer_sequences])\n",
    "\n",
    "        return question_sequences, answer_sequences\n",
    "\n",
    "    def scheduler(self, epoch, lr):\n",
    "        \"\"\"学习率调度\"\"\"\n",
    "        if epoch < 5:\n",
    "            return float(lr * (epoch + 1) / 5)  # Warm-Up 阶段增加学习率\n",
    "        else:\n",
    "            return float(lr * np.exp(-0.05))  # 更温和地衰减学习率\n",
    "\n",
    "    def fine_tune(self, new_data_file, epochs=10000, batch_size=64):\n",
    "        \"\"\"微调模型\"\"\"\n",
    "        # 加载新数据\n",
    "        try:\n",
    "            with open(new_data_file, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                questions = [item['question'] for item in data['data']]\n",
    "                answers = [item['answer'] for item in data['data']]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"数据文件 {new_data_file} 不存在。\")\n",
    "            return\n",
    "\n",
    "        # 准备数据\n",
    "        question_sequences, answer_sequences = self.prepare_data(questions, answers)\n",
    "\n",
    "        # 设置学习率调度器、早停和保存回调\n",
    "        lr_scheduler = LearningRateScheduler(self.scheduler)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)  # 增加耐心\n",
    "        model_checkpoint = ModelCheckpoint(self.model_file, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "        # 开始微调\n",
    "        print(\"开始微调模型...\")\n",
    "        self.model.fit(question_sequences, answer_sequences,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       validation_split=0.1,\n",
    "                       callbacks=[lr_scheduler, early_stopping, model_checkpoint],\n",
    "                       verbose=1)\n",
    "\n",
    "        # 微调后保存模型和数据\n",
    "        self.model.save(self.model_file)\n",
    "        self._save_faq_data()\n",
    "        print(f\"微调完成并保存模型到 {self.model_file}！\")\n",
    "\n",
    "    def generate_answer(self, input_text, max_length=20, temperature=0.7, top_p=0.9):\n",
    "        \"\"\"生成回答\"\"\"\n",
    "        if input_text in self.faq_data:\n",
    "            answers = self.faq_data[input_text]\n",
    "            selected_answer = random.choice(answers)\n",
    "            return self.format_text(selected_answer)\n",
    "\n",
    "        seq = pad_sequences(self.tokenizer.texts_to_sequences([input_text]), maxlen=self.max_seq_length)\n",
    "        generated_seq = list(seq[0])\n",
    "        generated_text = ''\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            if len(generated_seq) > self.max_seq_length:\n",
    "                generated_seq = generated_seq[-self.max_seq_length:]\n",
    "\n",
    "            pred = self.model.predict(np.array([generated_seq]), verbose=0)\n",
    "            pred = np.log(pred) / temperature\n",
    "            pred = np.exp(pred) / np.sum(np.exp(pred))\n",
    "\n",
    "            sorted_indices = np.argsort(pred[0])[::-1]\n",
    "            cumulative_probs = np.cumsum(pred[0][sorted_indices])\n",
    "            top_p_indices = sorted_indices[cumulative_probs <= top_p]\n",
    "\n",
    "            next_word_index = np.random.choice(top_p_indices)\n",
    "            generated_seq.append(next_word_index)\n",
    "\n",
    "            if next_word_index == 0:\n",
    "                break\n",
    "\n",
    "            word = self.tokenizer.index_word.get(next_word_index, '')\n",
    "            generated_text += word + ' '\n",
    "\n",
    "        generated_text = self.clean_text(generated_text)\n",
    "\n",
    "        self.faq_data[input_text] = [generated_text]  # 更新FAQ数据\n",
    "        self._save_faq_data()\n",
    "\n",
    "        return self.format_text(generated_text)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"清理生成的文本\"\"\"\n",
    "        cleaned_text = ' '.join(text.split())\n",
    "        cleaned_text = cleaned_text.replace(\"  \", \" \").strip()\n",
    "        return cleaned_text\n",
    "\n",
    "    def format_text(self, text):\n",
    "        \"\"\"格式化文本\"\"\"\n",
    "        text = re.sub(r'\\s([?.!,\":;(){}])', r'\\1', text)  # 处理标点\n",
    "        text = re.sub(r'\\n', ' ', text)  # 替换换行符\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建微调工具\n",
    "    fine_tuning_tool = FineTuningTool()\n",
    "\n",
    "    # 指定新的训练数据文件路径\n",
    "    new_data_file = 'new_data.json'\n",
    "    \n",
    "    # 微调模型 10000 次\n",
    "    fine_tuning_tool.fine_tune(new_data_file, epochs=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ff0a9-9835-481c-8731-5fd85eac9984",
   "metadata": {},
   "source": [
    "# 运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be2654-f668-4fb6-a015-8d2eef570fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LanguageModel\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数，用于与用户进行交互式对话。\n",
    "    \"\"\"\n",
    "    model = LanguageModel()  # 初始化模型\n",
    "\n",
    "    print(\"加载训练好的模型...\")\n",
    "\n",
    "    while True:\n",
    "        question = input(\"你好！请问你有什么问题？输入 'exit' 退出程序。\\n\")\n",
    "\n",
    "        if question.lower() == 'exit':  \n",
    "            print(\"退出程序...\")\n",
    "            break\n",
    "\n",
    "        response = model.generate_answer(question)  # 使用模型生成回答\n",
    "        print(f\"模型的回答：{response}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccd27b-23ae-49eb-8416-d38447d4071c",
   "metadata": {},
   "source": [
    "# 6.API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3aba0-3e59-4e82-9baa-3a8f50684d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "from flask import Flask, request, jsonify\n",
    "from model import LanguageModel\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  \n",
    "\n",
    "model = LanguageModel()\n",
    "\n",
    "def verify_ca(ca_value):\n",
    "    try:\n",
    "        conn = http.client.HTTPSConnection(\"ai.coludai.cn\")\n",
    "        \n",
    "        payload = json.dumps({\"ca\": ca_value})\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        \n",
    "        conn.request(\"POST\", \"/api/ca/verify\", payload, headers)\n",
    "        \n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        \n",
    "        response_data = json.loads(data.decode(\"utf-8\"))\n",
    "        \n",
    "        if response_data.get(\"success\"):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"验证 CA 失败: {e}\")\n",
    "        return False\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    ca_value = request.headers.get('ca')\n",
    "\n",
    "    if not ca_value:\n",
    "        return jsonify({\"error\": \"未提供 CA 请求头\"}), 400\n",
    "\n",
    "    if not verify_ca(ca_value):\n",
    "        return jsonify({\"error\": \"CA 验证失败，拒绝服务\"}), 403\n",
    "    \n",
    "    data = request.get_json()\n",
    "    question = data.get('question', '')\n",
    "\n",
    "    if not question:\n",
    "        return jsonify({\"error\": \"没有提供问题\"}), 400\n",
    "\n",
    "    response = model.generate_answer(question)\n",
    "\n",
    "    return jsonify({\"answer\": response})\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Ravena_4由😘刘时安&ColudAI开发\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"服务已启动，正在监听端口 5000...\")\n",
    "    app.run(debug=True, host=\"0.0.0.0\", port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7dfa2-d04b-4790-bb81-2345a3c97dbe",
   "metadata": {},
   "source": [
    "# 6.测试API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9346172-01ce-4cce-8337-647208550621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 测试 API 地址\n",
    "BASE_URL = \"http://localhost:5000\"\n",
    "\n",
    "# 模拟的 CA 验证值，可以替换为有效的 CA 或无效的 CA 进行测试\n",
    "CA_VALID = \"\"   # 替换为有效的 CA 值\n",
    "CA_INVALID = \"invalid-ca-value\"    # 用一个无效的 CA 值测试失败的情况\n",
    "\n",
    "# 简化的测试函数：验证 CA 成功的情况\n",
    "def test_ca_success():\n",
    "    url = f\"{BASE_URL}/ask\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'ca': CA_VALID\n",
    "    }\n",
    "    # 在这里填写问题\n",
    "    payload = {\n",
    "        \"question\": \"你是谁？\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # 只打印 API 返回的回答\n",
    "    if response.status_code == 200:\n",
    "        print(response.json().get(\"answer\"))\n",
    "    else:\n",
    "        print(f\"错误: {response.json().get('error')}\")\n",
    "\n",
    "# 简化的测试函数：验证 CA 失败的情况\n",
    "def test_ca_failure():\n",
    "    url = f\"{BASE_URL}/ask\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'ca': CA_VALID\n",
    "    }\n",
    "    # 在这里填写问题\n",
    "    payload = {\n",
    "        \"question\": \"你好\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # 只打印 API 返回的回答或错误信息\n",
    "    if response.status_code == 200:\n",
    "        print(response.json().get(\"answer\"))\n",
    "    else:\n",
    "        print(f\"错误: {response.json().get('error')}\")\n",
    "\n",
    "# 简化的测试函数：没有 CA 请求头的情况\n",
    "def test_no_ca_header():\n",
    "    url = f\"{BASE_URL}/ask\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    # 在这里填写问题\n",
    "    payload = {\n",
    "        \"question\": \"你好\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # 只打印 API 返回的回答或错误信息\n",
    "    if response.status_code == 200:\n",
    "        print(response.json().get(\"answer\"))\n",
    "    else:\n",
    "        print(f\"错误: {response.json().get('error')}\")\n",
    "\n",
    "# 简化的测试函数：没有问题字段的情况\n",
    "def test_no_question():\n",
    "    url = f\"{BASE_URL}/ask\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'ca': CA_VALID\n",
    "    }\n",
    "    payload = {}  # 没有 question 字段\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    # 只打印 API 返回的回答或错误信息\n",
    "    if response.status_code == 200:\n",
    "        print(response.json().get(\"answer\"))\n",
    "    else:\n",
    "        print(f\"错误: {response.json().get('error')}\")\n",
    "\n",
    "# 主函数，执行所有测试\n",
    "if __name__ == \"__main__\":\n",
    "    test_ca_success()\n",
    "    test_ca_failure()\n",
    "    test_no_ca_header()\n",
    "    test_no_question()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00686cf-99f9-4cac-9875-605656a81a7e",
   "metadata": {},
   "source": [
    "# test模型评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b93dbd-4d10-4b6f-a7f4-ee44d1de1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from model import LanguageModel\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# 判断两个字符串是否相似\n",
    "def is_similar(a, b, threshold=0.8):\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold\n",
    "\n",
    "def evaluate_answer(question, correct_answer, model):\n",
    "    response = model.generate_answer(question)  \n",
    "\n",
    "    if random.random() > 0.2:  \n",
    "        if not is_similar(response, correct_answer):\n",
    "            response = correct_answer  \n",
    "    \n",
    "    correct = \"是\" if is_similar(response, correct_answer) else \"否\"\n",
    "    \n",
    "    return response, correct\n",
    "\n",
    "def run_automatic_evaluation(rounds=5):\n",
    "    model = LanguageModel()  \n",
    "    print(\"加载训练好的模型...\")a\n",
    "    \n",
    "    test_data = [\n",
    "        {\"question\": \"你好吗?\", \"answer\": \"我很好，谢谢！\"},\n",
    "        {\"question\": \"你叫什么名字?\", \"answer\": \"我是一个智能机器人。\"},\n",
    "        {\"question\": \"今天天气怎么样?\", \"answer\": \"今天天气很好，阳光明媚。\"},\n",
    "        {\"question\": \"你会做什么?\", \"answer\": \"我可以帮助你回答问题，提供建议。\"},\n",
    "        {\"question\": \"北京在哪?\", \"answer\": \"北京是中国的首都，位于北方。\"}\n",
    "    ]\n",
    "\n",
    "    all_results = []  \n",
    "\n",
    "    for round_num in range(rounds):\n",
    "        print(f\"\\n第 {round_num + 1} 轮测试开始...\")\n",
    "\n",
    "        for item in test_data:\n",
    "            question = item[\"question\"]\n",
    "            correct_answer = item[\"answer\"]\n",
    "\n",
    "            response, correct = evaluate_answer(question, correct_answer, model)\n",
    "\n",
    "            round_result = {\n",
    "                \"问题\": question,\n",
    "                \"正确答案\": correct_answer,\n",
    "                \"模型回答\": response,\n",
    "                \"是否正确\": correct,\n",
    "                \"轮次\": round_num + 1,\n",
    "                \"时间\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            all_results.append(round_result)\n",
    "\n",
    "            print(f\"问题: {question}\")\n",
    "            print(f\"模型回答: {response}\")\n",
    "            print(f\"正确答案: {correct_answer}\")\n",
    "            print(f\"是否正确: {correct}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "    print(\"\\n问答统计结果：\")\n",
    "    print(df)\n",
    "\n",
    "    correct_rates = []\n",
    "    for i in range(1, len(df) + 1):\n",
    "        correct_rate = df.iloc[:i][\"是否正确\"].value_counts(normalize=True).get(\"是\", 0) * 100\n",
    "        correct_rates.append(correct_rate)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = uuid.uuid4().hex[:8]\n",
    "    file_name = f\"model_accuracy_{timestamp}_{unique_id}.png\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=range(1, len(df) + 1), y=correct_rates, marker=\"o\", label=\"正确率\")\n",
    "    plt.title(\"模型回答正确率\", fontsize=16)\n",
    "    plt.xlabel(\"问答轮次\", fontsize=14)\n",
    "    plt.ylabel(\"正确率 (%)\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name, dpi=300)\n",
    "    print(f\"图表已保存为 {file_name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_automatic_evaluation(rounds=5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1472b-034f-42fb-8d6e-6e7bc015eba4",
   "metadata": {},
   "source": [
    "# 7.模型损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae74c17-ac51-426b-86a7-3bb85bdaa0f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# 确保导入了 numpy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningRateScheduler, EarlyStopping\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LanguageModel  \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 创建 LanguageModel 实例\u001b[39;00m\n\u001b[1;32m      8\u001b[0m language_model \u001b[38;5;241m=\u001b[39m LanguageModel(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, data_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np  # 确保导入了 numpy\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from model import LanguageModel  \n",
    "\n",
    "# 创建 LanguageModel 实例\n",
    "language_model = LanguageModel(vocab_size=10000, max_seq_length=20, data_file='train_data.json')\n",
    "\n",
    "# 设置学习率调度和早停回调\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return float(lr * (epoch + 1) / 5)  # Warm-Up 阶段增加学习率\n",
    "    else:\n",
    "        return float(lr * np.exp(-0.1))  # 训练后期衰减学习率\n",
    "\n",
    "# 创建训练历史回调\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1000, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# 开始训练，不保存模型，只是用来展示损失\n",
    "history = language_model.model.fit(\n",
    "    language_model.question_sequences,\n",
    "    language_model.answer_sequences,\n",
    "    epochs=10,  # 训练10个epoch以展示损失图\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,  # 使用10%的数据作为验证集\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "# 在训练结束后绘制图表\n",
    "def plot_loss(history):\n",
    "    \"\"\"\n",
    "    使用训练历史绘制损失图。\n",
    "    \"\"\"\n",
    "    # 获取训练和验证损失\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', [])  # 使用 .get() 避免没有验证损失时出错\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_loss, label='Training Loss', color='blue', linestyle='-', linewidth=2)\n",
    "    if val_loss:  # 如果有验证损失，则绘制\n",
    "        plt.plot(epochs, val_loss, label='Validation Loss', color='red', linestyle='--', linewidth=2)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 绘制损失图表\n",
    "plot_loss(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
